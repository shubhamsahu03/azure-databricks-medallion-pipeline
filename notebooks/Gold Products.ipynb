{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dbc2308-62be-492b-8cca-19f608a22676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##**DLT Pipeline**\n",
    "\n",
    "###**Streaming Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63eab98f-ebe4-4928-b53f-e23aaca35ff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected internal error when monkey patching dlt module: cannot import name 'overrides' from partially initialized module 'dlt' (most likely due to a circular import) (/local_disk0/.ephemeral_nfs/envs/pythonEnv-a16e8c6c-df3b-498e-af33-2a6847683cf5/lib/python3.11/site-packages/dlt/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "%python\n",
    "\n",
    "import dlt\n",
    "\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15ee5e4a-67ba-4e9b-a52a-debe4f8d174b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt import table, view,expect_all_or_drop,create_streaming_table,apply_changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50c7bd66-6b01-4a86-9a05-69964edc32fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4d48b3b-6d9b-4249-a421-fe0233adc755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Expectations\n",
    "my_rules={\n",
    "    \"rule1\":\"product_id is NOT NULL\",\n",
    "    \"rule2\":\"product_name is NOT NULL\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bad0a27-c61a-4e45-834b-645f4579e64f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-6994793885996875>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;129m@dlt\u001B[39m\u001B[38;5;241m.\u001B[39mtable\n",
       "\u001B[1;32m      2\u001B[0m \n",
       "\u001B[0;32m----> 3\u001B[0m \u001B[38;5;129m@dlt\u001B[39m\u001B[38;5;241m.\u001B[39mexpect_all_or_drop(my_rules)\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mDimProducts_stage\u001B[39m():\n",
       "\u001B[1;32m      5\u001B[0m     df\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mreadStream\u001B[38;5;241m.\u001B[39mtable(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks_cat.silver.products_silver\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a16e8c6c-df3b-498e-af33-2a6847683cf5/lib/python3.11/site-packages/dlt/api.py:224\u001B[0m, in \u001B[0;36mexpect_all_or_drop\u001B[0;34m(expectations)\u001B[0m\n",
       "\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexpect_all_or_drop\u001B[39m(\n",
       "\u001B[1;32m    215\u001B[0m     expectations: Dict[\u001B[38;5;28mstr\u001B[39m, Union[\u001B[38;5;28mstr\u001B[39m, Column]],\n",
       "\u001B[1;32m    216\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Callable[[Callable[[], DataFrame]], Callable[[], DataFrame]]:\n",
       "\u001B[1;32m    217\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    218\u001B[0m \u001B[38;5;124;03m    Adds multiple drop expectations on the contents of this dataset. Unexpected records (i.e those\u001B[39;00m\n",
       "\u001B[1;32m    219\u001B[0m \u001B[38;5;124;03m    where the invariant does not evaluate to true) will be counted and dropped.\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    222\u001B[0m \u001B[38;5;124;03m        invariant (string or Column) that will be checked on the dataset.\u001B[39;00m\n",
       "\u001B[1;32m    223\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 224\u001B[0m     __local_execution_disabled()\n",
       "\u001B[1;32m    225\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __outer\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a16e8c6c-df3b-498e-af33-2a6847683cf5/lib/python3.11/site-packages/dlt/api.py:31\u001B[0m, in \u001B[0;36m__local_execution_disabled\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m     29\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(error_msg)\n",
       "\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m---> 31\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(error_msg)\n",
       "\n",
       "\u001B[0;31mException\u001B[0m: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Exception",
        "evalue": "This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>Exception</span>: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-6994793885996875>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;129m@dlt\u001B[39m\u001B[38;5;241m.\u001B[39mtable\n\u001B[1;32m      2\u001B[0m \n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;129m@dlt\u001B[39m\u001B[38;5;241m.\u001B[39mexpect_all_or_drop(my_rules)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mDimProducts_stage\u001B[39m():\n\u001B[1;32m      5\u001B[0m     df\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mreadStream\u001B[38;5;241m.\u001B[39mtable(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks_cat.silver.products_silver\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a16e8c6c-df3b-498e-af33-2a6847683cf5/lib/python3.11/site-packages/dlt/api.py:224\u001B[0m, in \u001B[0;36mexpect_all_or_drop\u001B[0;34m(expectations)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexpect_all_or_drop\u001B[39m(\n\u001B[1;32m    215\u001B[0m     expectations: Dict[\u001B[38;5;28mstr\u001B[39m, Union[\u001B[38;5;28mstr\u001B[39m, Column]],\n\u001B[1;32m    216\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Callable[[Callable[[], DataFrame]], Callable[[], DataFrame]]:\n\u001B[1;32m    217\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;124;03m    Adds multiple drop expectations on the contents of this dataset. Unexpected records (i.e those\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;124;03m    where the invariant does not evaluate to true) will be counted and dropped.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;124;03m        invariant (string or Column) that will be checked on the dataset.\u001B[39;00m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 224\u001B[0m     __local_execution_disabled()\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __outer\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a16e8c6c-df3b-498e-af33-2a6847683cf5/lib/python3.11/site-packages/dlt/api.py:31\u001B[0m, in \u001B[0;36m__local_execution_disabled\u001B[0;34m()\u001B[0m\n\u001B[1;32m     29\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(error_msg)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 31\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(error_msg)\n",
        "\u001B[0;31mException\u001B[0m: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dlt.table\n",
    "\n",
    "@dlt.expect_all_or_drop(my_rules)\n",
    "def DimProducts_stage():\n",
    "    df=spark.readStream.table(\"databricks_cat.silver.products_silver\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ede39ea-dce4-4867-98c3-21eb5f48b746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Streaming Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ba67926-4128-490a-afb1-9652256748be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-41806e6b-cef7-4f11-a0ec-30cccb7aeb80/lib/python3.11/site-packages/dlt/api.py:29: UserWarning: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code.\n  warnings.warn(error_msg)\n"
     ]
    }
   ],
   "source": [
    "@dlt.view\n",
    "def DimProducts_view():\n",
    "    df=spark.readStream.table(\"Live.DimProducts_stage\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9d2920d-7937-49f6-a28f-645de4747c70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##**DimProducts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db7b0622-de80-4e2d-a837-adc0cd7b7d91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-41806e6b-cef7-4f11-a0ec-30cccb7aeb80/lib/python3.11/site-packages/dlt/api.py:29: UserWarning: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code.\n  warnings.warn(error_msg)\n"
     ]
    }
   ],
   "source": [
    "dlt.create_streaming_table(\"DimProducts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f04c6085-2183-44ba-886d-0eca2508452b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-41806e6b-cef7-4f11-a0ec-30cccb7aeb80/lib/python3.11/site-packages/dlt/api.py:29: UserWarning: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code.\n  warnings.warn(error_msg)\n"
     ]
    }
   ],
   "source": [
    "dlt.apply_changes(\n",
    "    target = \"DimProducts\",\n",
    "    source = \"DimProducts_view\",\n",
    "    keys = [\"product_id\"],\n",
    "    sequence_by='product_id',\n",
    "    stored_as_scd_type = 2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold Products",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}